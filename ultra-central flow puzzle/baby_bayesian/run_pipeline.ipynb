!pip install pyDOE2 h5py matplotlib numpy

import numpy as np
import pandas as pd
import h5py
import subprocess
import matplotlib.pyplot as plt
from pyDOE2 import lhs
from pathlib import Path

# =====================================
# GLOBAL CONFIG
# =====================================
N_DESIGN = 10          # number of LHS points (increase later)
N_EVENTS = 50000       # events per design point
UC_PERCENT = 1.0       # ultra-central cut
SEED0 = 1234

OUTDIR = Path("baby_bayes_results")
OUTDIR.mkdir(exist_ok=True)

TRENTO = "/root/.local/bin/trento"

# Collision energy choice
SIGMA_NN = 7.0     # fm^2 (5.02 TeV)
NORM = 18.38       # GeV (5.02 TeV)
# SIGMA_NN = 6.4   # 2.76 TeV
# NORM = 13.94

# =====================================
# PARAMETER RANGES
# =====================================
param_ranges = {
    "p": (-0.5, 0.5),
    "w": (0.4, 1.0),
    "sigma_k": (0.6, 1.2),
    "d": (1.0, 1.5)
}

param_names = list(param_ranges.keys())
ndim = len(param_names)

lhs_unit = lhs(ndim, samples=N_DESIGN)

design = np.zeros_like(lhs_unit)

for i, p in enumerate(param_names):
    lo, hi = param_ranges[p]
    design[:, i] = lo + (hi - lo) * lhs_unit[:, i]

np.savetxt(
    OUTDIR / "design_points.txt",
    design,
    header=" ".join(param_names)
)

def select_ultracentral(events, percentile):
    mult = np.array([ev.attrs["mult"] for ev in events])
    idx = np.argsort(mult)[::-1]
    n_uc = int(len(mult) * percentile / 100)
    return [events[i] for i in idx[:n_uc]]

def eps_cumulants(eps):
    e2 = np.sqrt(np.mean(eps**2))
    e4_val = 2*np.mean(eps**2)**2 - np.mean(eps**4)
    e4 = e4_val**0.25 if e4_val > 0 else np.nan
    return e2, e4
    
results = []

for i, theta in enumerate(design):
    p, w, sigma_k, d = theta
    k = 1.0 / sigma_k**2
    seed = SEED0 + i

    out_hdf = OUTDIR / f"events_design_{i}.hdf"

    cmd = (
        f"{TRENTO} Pb Pb {N_EVENTS} "
        f"-p {p:.4f} -k {k:.4f} -w {w:.4f} -d {d:.4f} "
        f"-x {SIGMA_NN} -n {NORM} "
        f"--random-seed {seed} "
        f"--quiet --output {out_hdf}"
    )

    print(f"\nâ–¶ Running design point {i}")
    subprocess.run(cmd, shell=True, check=True)

    # -------------------------
    # Load and analyze
    # -------------------------
    with h5py.File(out_hdf, "r") as f:
        events = list(f.values())

    uc_events = select_ultracentral(events, UC_PERCENT)

    eps2 = np.array([ev.attrs["e2"] for ev in uc_events])
    eps3 = np.array([ev.attrs["e3"] for ev in uc_events])

    e22, e24 = eps_cumulants(eps2)
    e32, _ = eps_cumulants(eps3)

    results.append({
        "p": p,
        "w": w,
        "sigma_k": sigma_k,
        "d": d,
        "eps2{2}": e22,
        "eps2{4}": e24,
        "eps3{2}": e32,
        "eps2{2}/eps3{2}": e22 / e32,
        "eps2{4}/eps2{2}": e24 / e22
    })


df = pd.DataFrame(results)
df.to_csv(OUTDIR / "ultracentral_observables.csv", index=False)

df

plt.figure()
plt.scatter(df["eps3{2}"], df["eps2{2}"], s=60)
plt.xlabel(r"$\varepsilon_3\{2\}$")
plt.ylabel(r"$\varepsilon_2\{2\}$")
plt.title("Ultra-central eccentricities (design scan)")
plt.tight_layout()
plt.savefig(OUTDIR / "eps2_vs_eps3.pdf")
plt.show()

plt.figure()
plt.scatter(df["p"], df["eps2{2}/eps3{2}"], s=60)
plt.xlabel(r"$p$")
plt.ylabel(r"$\varepsilon_2\{2\}/\varepsilon_3\{2\}$")
plt.title("Ultra-central flow puzzle diagnostic")
plt.tight_layout()
plt.savefig(OUTDIR / "ratio_vs_p.pdf")
plt.show()

plt.figure()
plt.scatter(df["sigma_k"], df["eps2{4}/eps2{2}"], s=60)
plt.xlabel(r"$\sigma_k$")
plt.ylabel(r"$\varepsilon_2\{4\}/\varepsilon_2\{2\}$")
plt.title("Geometry vs fluctuations")
plt.tight_layout()
plt.savefig(OUTDIR / "eps24_ratio.pdf")
plt.show()

